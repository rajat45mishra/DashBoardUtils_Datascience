{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.formatcalculator import FormatCalculator\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# reads df from csv\n",
    "df = pd.read_csv(\"testdata.csv\")\n",
    "\n",
    "# that extracts formats from dataframe\n",
    "format_hashed_df = FormatCalculator.hash_df_formats(df)\n",
    "\n",
    "# get Unique formats from data\n",
    "unique_data = FormatCalculator.get_unique_hashes_from_df_columnwise(format_hashed_df)\n",
    "# optimised lists of unique data formats\n",
    "final_formatted_data = []\n",
    "for x in list(unique_data):\n",
    "    final_formatted_data.append((x[0], x[1]))\n",
    "# unique lables for data visualisation purposes\n",
    "unique_lables = [x[0] for x in final_formatted_data]\n",
    "getting_unique_label_data = [x[1] for x in final_formatted_data]\n",
    "# unique lables data format for all data format types in dataset\n",
    "sub_lables_unique_lables = (\n",
    "    pd.Series(list(itertools.chain(*getting_unique_label_data))).unique().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = []\n",
    "for ss,x in enumerate(df.columns.to_list()):\n",
    "    sub_lables = [\n",
    "        {x: [0 for z in range(len(unique_lables))]} for x in sub_lables_unique_lables\n",
    "    ]\n",
    "    values = df[x].values.tolist()\n",
    "    for z in sub_lables_unique_lables:\n",
    "        for xs in values:\n",
    "            import re\n",
    "            if re.compile(z).match(str(xs).strip()):\n",
    "                sub = [i for i, d in enumerate(sub_lables) if list(d.keys())[0] == z][0]\n",
    "                sub_lables[sub][z][ss] += 1\n",
    "    col.append([[q for q in list(de.values())[0] if q != 0] for de in sub_lables])\n",
    "\n",
    "sub_lables = [\n",
    "    {x: [0 for z in range(len(unique_lables))]} for x in sub_lables_unique_lables\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dogged_from(data, title):\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.models import ColumnDataSource,FactorRange,LabelSet\n",
    "    label_data = data[list(data.keys())[0]]\n",
    "    catagories = list(data.keys())[1:]\n",
    "    sq = []\n",
    "    x = [ (label, catagory) for label in label_data for catagory in catagories ]\n",
    "    counts = sum(zip(*[data[xa] for xa in catagories]),())\n",
    "    source = ColumnDataSource(data=dict(x=x,counts=counts))\n",
    "    labels = LabelSet(x='x', y='counts', text='counts', level='glyph',\n",
    "                  text_align='center', y_offset=5, source=source)\n",
    "    p = figure(x_range=FactorRange(*x), height=1800, title=title,\n",
    "           toolbar_location=None, tools=\"\",output_backend=\"svg\",width=18000)\n",
    "    p.vbar(x='x', top='counts', width=0.9, source=source, line_color=\"white\")\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.add_layout(labels)\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Call once to configure Bokeh to display plots inline in the notebook.\n",
    "# export_png(build_dogged_from(daat, \"Table formats visualise columnwise\"), filename=\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 True\n",
      "1 True\n",
      "2 True\n",
      "0 True\n",
      "-1 True\n",
      "-2 True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/rajat/Desktop/DashBoardBuilder/plot.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regex_filter(val,regex):\n",
    "    if val:\n",
    "        mo = re.fullmatch(regex,str(val).strip())\n",
    "        if mo:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "formatted_counts=[]\n",
    "for x in final_formatted_data:\n",
    "    da={}\n",
    "    for z in x[1]:\n",
    "        df[x[0]]=[str(sw) for sw in df[x[0]].values.tolist()]\n",
    "        df_co=df[x[0]].apply(regex_filter,regex=z)\n",
    "        df_co=df_co.loc[lambda x : x == True]\n",
    "        da[z]=df_co.count()\n",
    "        if x[0]==str(3):\n",
    "            for xq in df[x[0]].unique().tolist():\n",
    "                if re.match(z,str(xq)):\n",
    "                    print(xq,True)\n",
    "    formatted_counts.append((x[0],da))\n",
    "\n",
    "\n",
    "for i,x in enumerate(formatted_counts):\n",
    "    colindex=i\n",
    "    vals=list(x[1].keys())\n",
    "    for xs in vals:\n",
    "        subindex=[z for z,mi in enumerate(sub_lables) if list(mi.keys())[0]==xs]\n",
    "        sub_lables[subindex[0]][xs][colindex]=x[1][xs]\n",
    "\n",
    "    \n",
    "\n",
    "# graph constructor\n",
    "daat = {\"lables\": unique_lables}\n",
    "for x in sub_lables:\n",
    "    if list(x.keys())[0] != \"\":\n",
    "        daat.update(x)\n",
    "\n",
    "\n",
    "\n",
    "from bokeh.io import export_png\n",
    "\n",
    "# Call once to configure Bokeh to display plots inline in the notebook.\n",
    "export_png(build_dogged_from(daat, \"Table formats visualise columnwise\"), filename=\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', ['\\\\d{1}', '\\\\-\\\\d{1}']),\n",
       " ('?', ['\\\\?', '\\\\d{1}\\\\d{1}\\\\d{1}', '\\\\d{1}\\\\d{1}']),\n",
       " ('alfa-romero',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}\\\\-[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}\\\\-[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[A-Z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}\\\\-[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('gas',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('std',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}', '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('two',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}', '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}', '\\\\?']),\n",
       " ('convertible',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('rwd', ['[a-z]{1}[a-z]{1}[a-z]{1}', '\\\\d{1}[a-z]{1}[a-z]{1}']),\n",
       " ('front',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('88.6', ['\\\\d{1}\\\\d{1}\\\\.\\\\d{1}', '\\\\d{1}\\\\d{1}\\\\d{1}\\\\.\\\\d{1}']),\n",
       " ('168.8', ['\\\\d{1}\\\\d{1}\\\\d{1}\\\\.\\\\d{1}']),\n",
       " ('64.1', ['\\\\d{1}\\\\d{1}\\\\.\\\\d{1}']),\n",
       " ('48.8', ['\\\\d{1}\\\\d{1}\\\\.\\\\d{1}']),\n",
       " ('2548', ['\\\\d{1}\\\\d{1}\\\\d{1}\\\\d{1}']),\n",
       " ('dohc',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('four',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('130', ['\\\\d{1}\\\\d{1}\\\\d{1}', '\\\\d{1}\\\\d{1}']),\n",
       " ('mpfi',\n",
       "  ['[a-z]{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '\\\\d{1}[a-z]{1}[a-z]{1}[a-z]{1}',\n",
       "   '[a-z]{1}[a-z]{1}[a-z]{1}']),\n",
       " ('3.47', ['\\\\d{1}\\\\.\\\\d{1}\\\\d{1}', '\\\\d{1}\\\\.\\\\d{1}', '\\\\?']),\n",
       " ('2.68', ['\\\\d{1}\\\\.\\\\d{1}\\\\d{1}', '\\\\d{1}\\\\.\\\\d{1}', '\\\\?']),\n",
       " ('9', ['\\\\d{1}\\\\.\\\\d{1}', '\\\\d{1}\\\\d{1}\\\\.\\\\d{1}', '\\\\d{1}\\\\.\\\\d{1}\\\\d{1}']),\n",
       " ('111', ['\\\\d{1}\\\\d{1}\\\\d{1}', '\\\\d{1}\\\\d{1}', '\\\\?']),\n",
       " ('5000', ['\\\\d{1}\\\\d{1}\\\\d{1}\\\\d{1}', '\\\\?']),\n",
       " ('21', ['\\\\d{1}\\\\d{1}']),\n",
       " ('27', ['\\\\d{1}\\\\d{1}', '\\\\-\\\\d{1}']),\n",
       " ('13495',\n",
       "  ['\\\\d{1}\\\\d{1}\\\\d{1}\\\\d{1}\\\\d{1}', '\\\\?', '\\\\d{1}\\\\d{1}\\\\d{1}\\\\d{1}'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[A-Z]{3}\\\\-\\\\d{1}\\\\-\\\\s\\\\d{1}[A-Z]{1}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print repeted patterns from string\n",
    "\n",
    "\n",
    "def string_pattern_fetch(str, rowhash, ranged=0, values=[], **kwargs):\n",
    "    if str == \"\":\n",
    "        return values\n",
    "    rowhash += str[ranged]\n",
    "    if rowhash == str[0 : len(rowhash)]:\n",
    "        try:\n",
    "            if re.compile(rowhash):\n",
    "                str = str[len(rowhash) :]\n",
    "                values.append(rowhash)\n",
    "                rowhash = \"\"\n",
    "                return string_pattern_fetch(str, rowhash, ranged=0, values=values)\n",
    "        except Exception as E:\n",
    "            return string_pattern_fetch(str, rowhash, ranged=ranged + 1, values=values)\n",
    "    else:\n",
    "        return string_pattern_fetch(str, rowhash, ranged=ranged + 1, values=values)\n",
    "\n",
    "\n",
    "values = string_pattern_fetch(\n",
    "    \"[A-Z]{1}[A-Z]{1}[A-Z]{1}\\\\-\\\\d{1}\\\\-\\\\s\\\\d{1}[A-Z]{1}\", \"\"\n",
    ")\n",
    "\n",
    "finalvalue = []\n",
    "for xd in values:\n",
    "    if len(xd) > 1:\n",
    "        finalvalue.append(xd)\n",
    "    else:\n",
    "        finalvalue[-1] += xd\n",
    "\n",
    "\n",
    "def regex_updates(finalvalue, seq, hashs=\"\"):\n",
    "    if hashs == \"\":\n",
    "        hashs += finalvalue[0]\n",
    "    else:\n",
    "        core = finalvalue[seq]\n",
    "        if hashs[0:-3] == core[0:-3]:\n",
    "            hashw = list(hashs)\n",
    "            hashw[-2] = str(int(hashs[-2]) + 1)\n",
    "            hashs = \"\".join(hashw)\n",
    "        else:\n",
    "            hashs += core\n",
    "        if seq == len(finalvalue) - 1:\n",
    "            return hashs\n",
    "    return regex_updates(finalvalue, seq + 1, hashs=hashs)\n",
    "\n",
    "\n",
    "regex_updates(finalvalue, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any dataset in df\n",
    "import pandas as pd\n",
    "from package.keyborddata import *\n",
    "import re\n",
    "\n",
    "\n",
    "def regex_filter(val, regex):\n",
    "    if val == 0:\n",
    "        val = str(val)\n",
    "    if val:\n",
    "        mo = re.fullmatch(regex, str(val))\n",
    "        if mo:\n",
    "            return val\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"testdata.csv\")\n",
    "\n",
    "# that extracts formats from dataframe\n",
    "format_hashed_df = FormatCalculator.hash_df_formats(data)\n",
    "keyboards = alphabets + alphabets_upper + simbols + [str(x) for x in numbers]\n",
    "# get column format wise data length\n",
    "finaldata = []\n",
    "for x in format_hashed_df.columns.to_list():\n",
    "    colms = format_hashed_df[x].values.tolist()\n",
    "    my_list_count1 = {i: colms.count(i) for i in colms}\n",
    "    finaldata.append({x: my_list_count1})\n",
    "\n",
    "# formatwisedata org\n",
    "formatdataset = []\n",
    "hashed = []\n",
    "for x in finaldata:\n",
    "    hashed_x = x\n",
    "    for z in list(list(x.values())[0].keys()):\n",
    "        datas = data[list(x.keys())[0]].apply(regex_filter, regex=z)\n",
    "        datas = datas[datas != False].values.tolist()\n",
    "        x[list(x.keys())[0]][z] = datas\n",
    "        hashd = []\n",
    "        for sa in datas:\n",
    "            if len(str(sa)) == 1:\n",
    "                hashd.append(str(keyboards.index(str(sa))))\n",
    "            else:\n",
    "                pairs = []\n",
    "                for xs in list(str(sa)):\n",
    "                    pairs.append(str(keyboards.index(xs)))\n",
    "                hashd.append(str(pairs))\n",
    "\n",
    "        hashed_x[list(hashed_x.keys())[0]][z] = {i: hashd.count(i) for i in hashd}\n",
    "\n",
    "    formatdataset.append(x)\n",
    "    hashed.append(hashed_x)\n",
    "\n",
    "\n",
    "def dict_mapped_tup(dictionary):\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, dict):\n",
    "            yield from (\n",
    "                (key,) + subkey_value for subkey_value in dict_mapped_tup(value)\n",
    "            )\n",
    "        else:\n",
    "            yield key, value\n",
    "\n",
    "\n",
    "# multindex columns\n",
    "tuplesd = [list(dict_mapped_tup(x)) for x in hashed]\n",
    "tuplesd = [x for xs in tuplesd for x in xs]\n",
    "multindextuples = []\n",
    "valueslist = []\n",
    "for x in tuplesd:\n",
    "    multindextuples.append(x[:-1])\n",
    "    valueslist.append(x[-1])\n",
    "\n",
    "multindex = pd.MultiIndex.from_tuples(multindextuples)\n",
    "output_df_before_optimizing_unique_lists = pd.DataFrame([valueslist], columns=multindex)\n",
    "# write html to file\n",
    "text_file = open(\"table.html\", \"w\")\n",
    "text_file.write(output_df_before_optimizing_unique_lists.to_html())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi',\n",
       " 'audi']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data for  one or more columns\n",
    "import ast\n",
    "\n",
    "valueslis = []\n",
    "for x in output_df_before_optimizing_unique_lists.columns.to_list():\n",
    "    datasq = None\n",
    "    try:\n",
    "        datasq = int(x[-1])\n",
    "    except Exception as E:\n",
    "        datasq = ast.literal_eval(x[-1])\n",
    "    if type(datasq) == int:\n",
    "        generowscount = output_df_before_optimizing_unique_lists[x].values.tolist()[0]\n",
    "        datagen = [keyboards[int(datasq)] for d in range(generowscount)]\n",
    "        valueslis.append(datagen)\n",
    "    else:\n",
    "        generowscount = output_df_before_optimizing_unique_lists[x].values.tolist()[0]\n",
    "        datagen = [\n",
    "            \"\".join([keyboards[int(z)] for z in datasq]) for d in range(generowscount)\n",
    "        ]\n",
    "        valueslis.append(datagen)\n",
    "\n",
    "\n",
    "valueslis[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15275/638104438.py:59: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  testdf[col][val]=valueslist[s]\n"
     ]
    }
   ],
   "source": [
    "# we are extending locals and globles of our last tutorial\n",
    "# fetch all keyboard patterns from dataframe\n",
    "\n",
    "rowindexes = [x[-1] for x in multindextuples]\n",
    "updatedcols = [x[:-1] for x in multindextuples]\n",
    "rowsmultiindexint = []\n",
    "for x in rowindexes:\n",
    "    dataq = None\n",
    "    try:\n",
    "        dataq = int(x)\n",
    "    except Exception as E:\n",
    "        dataq = ast.literal_eval(x)\n",
    "    if type(dataq) == int:\n",
    "        dataq = [int(x)]\n",
    "    else:\n",
    "        dataq = [int(xa) for xa in dataq]\n",
    "    rowsmultiindexint.append(dataq)\n",
    "\n",
    "\n",
    "def FindMaxLength(lst):\n",
    "    maxLength = max(len(x) for x in lst)\n",
    "\n",
    "    return maxLength\n",
    "\n",
    "\n",
    "rowindexesdata = []\n",
    "for xs in rowsmultiindexint:\n",
    "    if len(xs) < FindMaxLength(rowsmultiindexint):\n",
    "        diff = FindMaxLength(rowsmultiindexint) - len(xs)\n",
    "        ws = [\"\" for z in range(diff)]\n",
    "        xs = ws + xs\n",
    "        rowindexesdata.append(tuple(xs))\n",
    "\n",
    "\n",
    "rowindexesdata = pd.MultiIndex.from_tuples(rowindexesdata)\n",
    "\n",
    "testdf = pd.DataFrame(\n",
    "    index=rowindexesdata, columns=pd.MultiIndex.from_tuples(list(set(updatedcols)))\n",
    ")\n",
    "latlong = []\n",
    "for xs in output_df_before_optimizing_unique_lists.columns.to_list():\n",
    "    lat = xs[:-1]\n",
    "    long=None\n",
    "    try:\n",
    "        long=[int(xs[-1])]\n",
    "    except Exception as E:\n",
    "        long = [int(z) for z in ast.literal_eval(xs[-1])]\n",
    "    latlong.append((lat, long))\n",
    "\n",
    "for s,g in enumerate(latlong):\n",
    "    val=None\n",
    "    col=None\n",
    "    for x in testdf.index.values.tolist():\n",
    "        \n",
    "        if x[len(x)-len(g[1]):]==tuple(g[1]):\n",
    "            val=x\n",
    "            col=g[0]\n",
    "    if val is not None and col is not None:\n",
    "        testdf[col][val]=valueslist[s]\n",
    "\n",
    "testdf.to_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajat/Desktop/DashBoardBuilder/package/formatcalculator.py:402: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  testdf[col][val] = valueslist[s]\n"
     ]
    }
   ],
   "source": [
    "from package.formatcalculator import FormatCalculator\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# reads df from csv\n",
    "df = pd.read_csv(\"testdata.csv\")\n",
    "mitter=FormatCalculator.generate_datamiter(df)\n",
    "mitter._df.to_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = './package/'\n",
    "\n",
    "for path, dirs, files in os.walk(PATH):\n",
    "    for f in files:\n",
    "        file_name, file_extension = os.path.splitext(f)\n",
    "        if file_extension == '.py':\n",
    "            path_name = os.path.join(path, f)\n",
    "            with open(path_name, 'r') as fh:\n",
    "                new = [line.rstrip() for line in fh]\n",
    "            with open(path_name, 'w') as fh:\n",
    "                [fh.write('%s\\n' % line) for line in new]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataclasses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
