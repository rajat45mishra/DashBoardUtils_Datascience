"""calulates formats of data

    Returns:
        List|str: formatclaculator class

    Yields:
        List: list
    """
import itertools
import ast
import re
from typing import List, Any
import pandas as pd
from package.keyborddata import alphabets, alphabets_upper, numbers, simbols


class Mitter:
    """returns mitter object for validation hasattr df for dataframe transformation"""

    def __init__(self, _df) -> None:
        self._df = _df


class FormatCalculator:

    """FormatCalculator class fetches formets from any type of data input
    data should be in df or records format and helps us to do \n
     analysis over it to fetch format and itration format and seeds from data
     then we must able to regenerate that data by having following receipies\n
        --- data formats\n
        --- itration format\n
        --- itration format seeds\n
        --- data format seeds\n
    Format Calculator class have following features\n
       -- regex_formattor (groups regex string and generate optimised
         regex generated by FormatCalculator inputargs:[cls,str])\n
       -- get_unique_hashes_from_data ( gets uniques hashes from data
         columns wise  inputargs:[cls,LIST[ANY]])\n
       -- split_all_labels_to_words_with_new_cols
       ( splits string and create new cols in dataframe
       inputargs:[cls,Dataframe,exer=[" "]])\n
       -- hash_df_single_df_column ( hashes single
       df col inputargs:[cls,pd.Series])\n
       -- hash_df_formats ( hashes all data in dataframe )
         inputargs:[cls,pd.Dataframe]\n
       -- get_unique_hashes_from_df_columnwise
       ( column wise hashes generater in records
       format inputargs:[cls,pd.DataFrame])\n

    """

    @classmethod
    def regex_formattor(cls, value):
        """(groups regex string and generate optimised
        regex generated by FormatCalculator inputargs:[cls,str])"""
        _s = "".join(ch for ch, _ in itertools.groupby(value))
        formats = [
            "[a-z]{1}",
            "[A-Z]{1}",
            "\\d{1}",
            "\\s",
            "-\\d{1}",
            "\\~",
            "\\@",
            "\\#",
            "\\$",
            "\\%",
            "\\^",
            "\\&",
            "\\*",
            "\\-",
            "\\_",
            "\\+",
            "\\=",
            "\\:",
            "\\;",
            "\\'",
            '\\"',
            "\\|",
            "\\,",
            "\\`",
            "\\?",
        ]
        hashs = []
        rowhash = ""
        for _x in _s:
            rowhash += _x
            if len(rowhash) == 8 and rowhash in formats:
                if hashs == []:
                    hashs.append(rowhash)
                else:
                    mat = hashs[-1][0:6] + "1" + hashs[-1][-1]
                    if mat == rowhash:
                        _ha = list(hashs[-1])
                        _ha[-2] = str(int(hashs[-1][-2]) + 1)
                        hashs[-1] = "".join(_ha)
                    else:
                        hashs.append(rowhash)
                rowhash = ""
            elif len(rowhash) == 2 and rowhash in formats:
                hashs.append(rowhash)
                rowhash = ""
            elif len(rowhash) == 5 and rowhash in formats:
                if hashs == []:
                    hashs.append(rowhash)
                else:
                    mat = hashs[-1][0:3] + "1" + hashs[-1][-1]
                    if mat == rowhash:
                        _ha = list(hashs[-1])
                        _ha[-2] = str(int(hashs[-1][-2]) + 1)
                        hashs[-1] = "".join(_ha)
                    else:
                        hashs.append(rowhash)
                rowhash = ""
            elif len(rowhash) == 1 and rowhash in formats:
                hashs.append(rowhash)
                rowhash = ""
        return "".join(hashs)

    @classmethod
    def get_unique_hashes_from_data(cls, chuncks: List[Any]):
        """( gets uniques hashes from data columns wise  inputargs:[cls,LIST[ANY]])"""

        _df = pd.DataFrame.from_records(chuncks).fillna("0")
        cols = _df.columns.to_list()
        df_list = []
        for _x in cols:
            _d = _df[_df[_x] != "0"]
            df_list.append(_d[_x])

        series_list = []
        for _s in df_list:
            lables = []
            for _e in _s:
                lables += _e["lables"]

            unique_lables = []
            for xsa in lables:
                if xsa not in unique_lables:
                    unique_lables.append(xsa)
            series_list.append(unique_lables)

        hash_list = []
        for _x in series_list:
            hash_lables = []
            for _q in _x:
                datalen = len(_q)
                hashd = r""
                for _xs in range(datalen):
                    if str(_q[_xs]) in alphabets:
                        hashd += "[a-z]{1}"
                    elif str(_q[_xs]) in alphabets_upper:
                        hashd += "[A-Z]{1}"
                    elif str(_q[_xs]) in simbols:
                        hashd += r"\{}".format(str(_q[_xs]))
                    else:
                        data = None
                        try:
                            data = int(_q[_xs])
                        except ValueError:
                            if _q[_xs] == " ":
                                hashd += r"\s"
                            else:
                                hashd += _q[_xs]
                        if data is not None:
                            hashd += r"\d{1}"
                hash_lables.append(hash)
            hash_list.append(hash_lables)

        unique_hashes = []
        for _i, _x in enumerate(hash_list):
            unique_hashes.append({cols[_i]: list(set(_x))})
        return unique_hashes

    @classmethod
    def split_all_labels_to_words_with_new_cols(cls, _df, exer: List[str] = None):
        """(splits string and create new cols in dataframe inputargs:[cls,Dataframe,exer=[" "]])"""

        if exer is None:
            exer = [
                " ",
            ]
        numdata = _df
        _df = _df.select_dtypes(include=["object"])
        cols_to_select = set(numdata.columns.to_list()) - set(_df.columns.to_list())
        result = _df.to_dict("records")
        cols = _df.columns.to_list()
        final_df = []
        for _v in result:
            for _x in cols:
                val = None
                for _s in exer:
                    if not isinstance(_v[_x], list):
                        if _s in _v[_x]:
                            val = _v[_x].split(_s)
                        else:
                            val = _v[_x]
                _v[_x] = val
            final_df.append(_v)
        df_list = []
        for _v in final_df:
            _cd = {}
            for _d, _n in _v.items():
                if isinstance(_n, list):
                    for i, _xs in enumerate(_n):
                        if i == 0:
                            _cd[_d] = _xs
                        else:
                            _cd["_".join([_d, str(i)])] = _xs
                else:
                    _cd[_d] = _n
            df_list.append(_cd)
        return pd.DataFrame.from_records(df_list).join(numdata[list(cols_to_select)])

    @classmethod
    def hash_df_single_df_column(cls, _series):
        """( hashes single df col inputargs:[cls,pd.Series])"""
        for k, _v in _series.items():
            hashd = ""
            for _x in str(_v):
                if str(_x) in alphabets:
                    hashd += "[a-z]{1}"
                elif str(_x) in alphabets_upper:
                    hashd += "[A-Z]{1}"
                elif str(_x) in simbols:
                    hashd += r"\{}".format(str(_x))
                else:
                    data = None
                    try:
                        data = int(_x)
                    except ValueError:
                        if _x == " ":
                            hashd += r"\s"
                        else:
                            hashd += _x
                    if data is not None:
                        hashd += r"\d{1}"
            yield k, hashd

    @classmethod
    def hash_df_formats(cls, _df):
        """( hashes all data in dataframe ) inputargs:[cls,pd.Dataframe]"""

        df_list = []
        for _x, _s in _df.iterrows():
            value = None
            idx = [sa[0] for sa in list(cls.hash_df_single_df_column(_s))]
            vals = [sw[1] for sw in list(cls.hash_df_single_df_column(_s))]
            value = pd.Series(vals, index=idx)
            df_list.append(value.to_dict())
        return pd.DataFrame.from_records(df_list)

    @classmethod
    def get_unique_hashes_from_df_columnwise(cls, _df):
        """( column wise hashes generater in records format inputargs:[cls,pd.DataFrame] )"""
        for _x in _df.columns.to_list():
            yield (_x, _df[_x].unique().tolist())

    @classmethod
    def regex_filter(cls, val, regex):
        """match regex function

        Args:
            val (str): value for pattern match
            regex (str): keyboard pattern

        Returns:
            str|bool: pattern match state
        """

        if val == 0:
            val = str(val)
        if isinstance(val, str):
            _mo = re.fullmatch(regex, str(val))
            if _mo:
                return val
            else:
                return False
        else:
            return False

    @classmethod
    def dict_mapped_tup(cls, dictionary):
        """_summary_

        Args:
            dictionary (Dict): convert dict to tuple

        Yields:
            Any: List of tuples
        """
        for key, value in dictionary.items():
            if isinstance(value, dict):
                yield from (
                    (key,) + subkey_value for subkey_value in cls.dict_mapped_tup(value)
                )
            else:
                yield key, value

    @classmethod
    def generate_datamiter(cls, _df):
        """generates data miter from df

        Args:
            df (dataframe): dataframe of data

        Returns:
            dataframe: returns multiindex dataframe
        """
        format_hashed_df = FormatCalculator.hash_df_formats(_df)
        keyboards = alphabets + alphabets_upper + simbols + [str(x) for x in numbers]
        # get column format wise data length
        finaldata = []
        for _x in format_hashed_df.columns.to_list():
            colms = format_hashed_df[_x].values.tolist()
            my_list_count1 = {i: colms.count(i) for i in colms}
            finaldata.append({_x: my_list_count1})
        # formatwisedata org
        formatdataset = []
        hashed = []
        for _x in finaldata:
            hashed_x = _x
            for _z in list(list(_x.values())[0].keys()):
                datas = _df[list(_x.keys())[0]].apply(cls.regex_filter, regex=_z)
                datas = datas[datas != False].values.tolist()
                _x[list(_x.keys())[0]][_z] = datas
                hashd = []
                for _sa in datas:
                    if len(str(_sa)) == 1:
                        hashd.append(str(keyboards.index(str(_sa))))
                    else:
                        pairs = []
                        for _xs in list(str(_sa)):
                            pairs.append(str(keyboards.index(_xs)))
                        hashd.append(str(pairs))
                hashed_x[list(hashed_x.keys())[0]][_z] = {
                    i: hashd.count(i) for i in hashd
                }

            formatdataset.append(_x)
            hashed.append(hashed_x)
        # multindex columns
        tuplesd = [list(cls.dict_mapped_tup(x)) for x in hashed]
        tuplesd = [x for xs in tuplesd for x in xs]
        multindextuples = []
        valueslist = []
        for _x in tuplesd:
            multindextuples.append(_x[:-1])
            valueslist.append(_x[-1])
        multindex = pd.MultiIndex.from_tuples(multindextuples)
        output_df_before_optimizing_unique_lists = pd.DataFrame(
            [valueslist], columns=multindex
        )
        rowindexes = [x[-1] for x in multindextuples]
        updatedcols = [x[:-1] for x in multindextuples]
        rowsmultiindexint = []
        for _x in rowindexes:
            dataq = None
            try:
                dataq = int(_x)
            except ValueError:
                dataq = ast.literal_eval(_x)
            if isinstance(dataq, int):
                dataq = [int(_x)]
            else:
                dataq = [int(xa) for xa in dataq]
            rowsmultiindexint.append(dataq)
        rowindexesdata = []
        for _xs in rowsmultiindexint:
            if len(_xs) < cls.find_max_length(rowsmultiindexint):
                diff = cls.find_max_length(rowsmultiindexint) - len(_xs)
                _ws = ["" for z in range(diff)]
                _xs = _ws + _xs
                rowindexesdata.append(tuple(_xs))

        rowindexesdata = pd.MultiIndex.from_tuples(rowindexesdata)

        testdf = pd.DataFrame(
            index=rowindexesdata,
            columns=pd.MultiIndex.from_tuples(list(set(updatedcols))),
        )
        latlong = []
        for _xs in output_df_before_optimizing_unique_lists.columns.to_list():
            lat = _xs[:-1]
            long = None
            try:
                long = [int(_xs[-1])]
            except ValueError:
                long = [int(z) for z in ast.literal_eval(_xs[-1])]
            latlong.append((lat, long))

        for _s, _g in enumerate(latlong):
            val = None
            col = None
            for _x in testdf.index.values.tolist():
                if _x[len(_x) - len(_g[1]) :] == tuple(_g[1]):
                    val = _x
                    col = _g[0]
            if val is not None and col is not None:
                testdf[col][val] = valueslist[_s]
        testdf = testdf.fillna("")
        return Mitter(testdf)

    @classmethod
    def find_max_length(cls, lst):
        """finds max length in list of lists

        Args:
            lst (LIST): list for find maxlength

        Returns:
            Int: max length
        """
        max_length = max(len(x) for x in lst)

        return max_length
